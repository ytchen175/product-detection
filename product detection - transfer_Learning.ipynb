{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vY3ynxE0v1tr",
    "outputId": "17223503-06f3-4a6d-81e6-f63ce8d674fb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.python.keras import optimizers\n",
    "# specifically for cnn\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten,Activation\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0KzjzBzwv1ty",
    "outputId": "637979ea-b9ef-41d7-d4f8-8c5e6eb48dfa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55585</th>\n",
       "      <td>9f89d9582e4d811330e83e3628b84114.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53785</th>\n",
       "      <td>0e506b549c296564b55ed42283b87f64.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53784</th>\n",
       "      <td>096f4541edcd6d8c209512f4a1a149a9.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53783</th>\n",
       "      <td>89e70f1b22897e15782cda74fae117fc.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53782</th>\n",
       "      <td>7f4c6b4f2177fa92d0d94b4ee2003ed3.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   filename  category\n",
       "55585  9f89d9582e4d811330e83e3628b84114.jpg         0\n",
       "53785  0e506b549c296564b55ed42283b87f64.jpg         0\n",
       "53784  096f4541edcd6d8c209512f4a1a149a9.jpg         0\n",
       "53783  89e70f1b22897e15782cda74fae117fc.jpg         0\n",
       "53782  7f4c6b4f2177fa92d0d94b4ee2003ed3.jpg         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pro_dir =  \"C:/Users/Landy/Desktop/Angela/prodetection2/\"\n",
    "# train_dir = \"C:/Users/Landy/Desktop/Angela/prodetection2/train/train/\"\n",
    "# test_dir = \"C:/Users/Landy/Desktop/Angela/prodetection2/test/test\"\n",
    "# train_df = pd.read_csv(\"C:/Users/Landy/Desktop/Angela/prodetection2/train.csv\")\n",
    "# train_df = train_df.sort_values(by='category',ascending=True)\n",
    "# train_df.head()\n",
    "pro_dir =  \"C:/Users/User/Desktop/prodetection/\"\n",
    "train_dir = \"C:/Users/User/Desktop/prodetection/train/train\"\n",
    "test_dir = \"C:/Users/User/Desktop/prodetection/test/test\"\n",
    "train_df = pd.read_csv(\"C:/Users/User/Desktop/prodetection/train.csv\")\n",
    "train_df = train_df.sort_values(by='category',ascending=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG_SIZE = 80\n",
    "IMG_SIZE = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "0     2683\n",
       "1     2702\n",
       "2     2687\n",
       "3     2703\n",
       "4     2703\n",
       "5     2641\n",
       "6     2641\n",
       "7     2660\n",
       "8     2700\n",
       "9     2698\n",
       "10    2672\n",
       "11    1843\n",
       "12    2691\n",
       "13    2682\n",
       "14    2684\n",
       "15    2632\n",
       "16    2665\n",
       "17    1553\n",
       "18    2103\n",
       "19    2679\n",
       "20    2653\n",
       "21    2598\n",
       "22    2623\n",
       "23    2540\n",
       "24    2705\n",
       "25    2692\n",
       "26    2684\n",
       "27    2702\n",
       "28    2561\n",
       "29    2138\n",
       "30    2705\n",
       "31    2677\n",
       "32    2157\n",
       "33     573\n",
       "34    2599\n",
       "35    2658\n",
       "36    2686\n",
       "37    1725\n",
       "38    2673\n",
       "39    2678\n",
       "40    2681\n",
       "41    2662\n",
       "Name: filename, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.0.0\n",
    "df = train_df.groupby('category')['filename'].nunique()\n",
    "#Series\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#隨機各抽573+存成dataframe\n",
    "# size = 573   # sample size\n",
    "# replace = True  # with replacement\n",
    "# fn = lambda obj: obj.loc[np.random.choice(obj.index, size, replace),:]\n",
    "# regular_df=train_df.groupby('category', as_index=False).apply(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>341b0262184add60b809aff3aed81833.jpg</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8153</th>\n",
       "      <td>54e53adaaa9008a0a8882d7bda6dfe71.jpg</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>ee555dbf81daaba395cfa2a6fbf11b82.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6781</th>\n",
       "      <td>d1816b72812038c113ba15e8f0a8fb2a.jpg</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>6ee1b33a162dbe24d6786329c1f64733.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20492</th>\n",
       "      <td>9dbe96caabf70bb1a4239f771a01ae96.jpg</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>289cca155a2c8e87e85c386f8dc5d575.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21408</th>\n",
       "      <td>fd2ec6ec670490d2b31b3b0e6746cbcc.jpg</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19054</th>\n",
       "      <td>9455d8cf6f38f906124e3c9384bda82c.jpg</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19851</th>\n",
       "      <td>45c53b84622c7d96674187998577ed2f.jpg</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24066 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   filename category\n",
       "8513   341b0262184add60b809aff3aed81833.jpg       14\n",
       "8153   54e53adaaa9008a0a8882d7bda6dfe71.jpg       14\n",
       "642    ee555dbf81daaba395cfa2a6fbf11b82.jpg        1\n",
       "6781   d1816b72812038c113ba15e8f0a8fb2a.jpg       11\n",
       "2153   6ee1b33a162dbe24d6786329c1f64733.jpg        3\n",
       "...                                     ...      ...\n",
       "20492  9dbe96caabf70bb1a4239f771a01ae96.jpg       35\n",
       "5215   289cca155a2c8e87e85c386f8dc5d575.jpg        9\n",
       "21408  fd2ec6ec670490d2b31b3b0e6746cbcc.jpg       37\n",
       "19054  9455d8cf6f38f906124e3c9384bda82c.jpg       33\n",
       "19851  45c53b84622c7d96674187998577ed2f.jpg       34\n",
       "\n",
       "[24066 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regular_df = regular_df.groupby('category')['filename'].nunique()\n",
    "#Series\n",
    "regular_df=pd.read_csv(pro_dir+'regular_df')\n",
    "regular_df.reset_index(drop=True,inplace=True)  \n",
    "# regular_df.to_csv('regular_df',index=False)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "regular_df=shuffle(regular_df)\n",
    "regular_df['category']=regular_df['category'].astype('str')\n",
    "regular_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df,valid_df=train_test_split(regular_df,test_size=0.2, shuffle = True, random_state=666, stratify=regular_df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "0     423\n",
       "1     427\n",
       "10    419\n",
       "11    408\n",
       "12    416\n",
       "13    415\n",
       "14    414\n",
       "15    418\n",
       "16    425\n",
       "17    395\n",
       "18    408\n",
       "19    409\n",
       "2     420\n",
       "20    426\n",
       "21    420\n",
       "22    410\n",
       "23    431\n",
       "24    437\n",
       "25    414\n",
       "26    417\n",
       "27    424\n",
       "28    431\n",
       "29    413\n",
       "3     423\n",
       "30    424\n",
       "31    428\n",
       "32    410\n",
       "33    312\n",
       "34    435\n",
       "35    412\n",
       "36    424\n",
       "37    409\n",
       "38    421\n",
       "39    423\n",
       "4     424\n",
       "40    423\n",
       "41    418\n",
       "5     412\n",
       "6     426\n",
       "7     413\n",
       "8     416\n",
       "9     430\n",
       "Name: filename, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df111= train_df.groupby('category')['filename'].nunique()\n",
    "train_df111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenamer=regular_df['filename'].tolist() \n",
    "path='C:\\\\Users\\\\User\\\\Desktop\\\\prodetection\\\\train_sample\\\\'\n",
    "# for filename in os.listdir(path):\n",
    "#     if filename not in filenamer:\n",
    "#         full_file_path = os.path.join(path, filename)\n",
    "#         os.remove(full_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uYaDRXElv1t3",
    "outputId": "4614bfcf-f238-48a4-a7dc-85bc4d70d32d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5689 validated image filenames belonging to 42 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40, # 角度值，0~180，影象旋轉\n",
    "    shear_range=0.2, # 隨機錯切換角度\n",
    "    validation_split = 0.13,\n",
    "    fill_mode='nearest' # 填充新建立畫素的方法\n",
    "\n",
    ")\n",
    "# # 1 2 4 7 8 14 16 28 56 112 941 1882 3764 6587 7528 13174 15056 26348 52696 \n",
    "# train_generator = datagen.flow_from_dataframe(\n",
    "#     dataframe=regular_df,\n",
    "#     directory = path,\n",
    "#     target_size=(IMG_SIZE,IMG_SIZE),\n",
    "#     subset=\"training\",\n",
    "#     # batch_size=int(len(train_df)/56),\n",
    "#     x_col='filename',\n",
    "#     y_col='category',\n",
    "#     batch_size=7110,\n",
    "#     shuffle=True,\n",
    "#     class_mode=\"categorical\"\n",
    "# )\n",
    "# #generator will return batch_x，batch_y\n",
    "# X, y = train_generator.next()\n",
    "\n",
    "# 1 2 4 7 8 14 16 28 56 112 941 1882 3764 6587 7528 13174 15056 26348 52696 \n",
    "train_df_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory = path,\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    subset=\"training\",\n",
    "    # batch_size=int(len(train_df)/56),\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    batch_size=5689,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "#generator will return batch_x，batch_y\n",
    "X_train, y_train = train_df_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1 2 4 7 8 14 16 28 56 112 941 1882 3764 6587 7528 13174 15056 26348 52696 \n",
    "valid_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=valid_df,\n",
    "    directory = path,\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    subset=\"validation\",\n",
    "    # batch_size=int(len(train_df)/56),\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    batch_size=212,\n",
    "    seed=666,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "#generator will return batch_x，batch_y\n",
    "X_valid, y_valid = valid_df_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle = True, random_state=666, stratify=y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YPojPhlvv1t7"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "data_name = \"convert_img(%s x %s)\" % (IMG_SIZE,IMG_SIZE)\n",
    "labels_name = \"labels(%s x %s)\" % (IMG_SIZE,IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cAMaXpzEv1t-",
    "outputId": "94bbe04c-5ef6-4fbc-ced0-43fb2b3c720c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved.\n"
     ]
    }
   ],
   "source": [
    "# save converted data as hdf5\n",
    "with h5py.File( pro_dir + data_name + '52696'+'.h5', 'w') as hf:\n",
    "    hf.create_dataset(data_name,  data=X )\n",
    "with h5py.File( pro_dir + labels_name + '52696'+'.h5', 'w') as hf:\n",
    "    hf.create_dataset(labels_name,  data=y)\n",
    "print(\"Successfully saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CC-MIEMjv1uB"
   },
   "outputs": [],
   "source": [
    "# X = []\n",
    "# y = []\n",
    "#read/write,file must exist\n",
    "# load model2\n",
    "# model2 = h5py.File( pro_dir +\"model2/model2\"+ '.h5', 'r')\n",
    "hfX = h5py.File( pro_dir + data_name +'.h5', 'r')\n",
    "hfy = h5py.File( pro_dir + labels_name +'.h5', 'r')\n",
    "    \n",
    "X = np.array(hfX[data_name][:]) #dataset_name is same as hdf5 object name \n",
    "y = np.array(hfy[labels_name][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y2MeFpMUv1uE",
    "outputId": "db1b5b04-2eda-4b8c-ac7a-31d188bb164a"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q68Y8ZXOv1uL",
    "outputId": "974ee445-a8ae-4d82-d5cb-62577498be87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7110, 256, 256, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.set_printoptions(threshold=np.inf)\n",
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PKpuR4-Nv1uP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import EfficientNetB3\n",
    "from efficientnet.tfkeras import EfficientNetB3\n",
    "\n",
    "# include_top=False(是否包含頂部(Top) 『完全連接層』)\n",
    "conv_base = EfficientNetB3(weights='imagenet',include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras.layers import LeakyReLU\n",
    "from tensorflow.python.keras import regularizers\n",
    "\n",
    "# model = models.Sequential()\n",
    "# model.add(conv_base)\n",
    "# model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
    "# # model.add(layers.Flatten(name=\"flatten\"))\n",
    "# # model.add(BatchNormalization())\n",
    "# # model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
    "# model.add(layers.Dense(42, activation='softmax', name=\"fc_out\"))\n",
    "# for layer in conv_base.layers:\n",
    "#     layer.trainable = False\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1024,kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(layers.Dropout(0.5))\n",
    "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
    "model.add(layers.Dense(42, activation='softmax', name=\"fc_out\"))\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in conv_base.layers:\n",
    "    if isinstance(layer, BatchNormalization):\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sai-6RiMv1uT",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b3 (Model)      (None, 8, 8, 1536)        10783528  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 1536)        0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8, 8, 1024)        1573888   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "fc_out (Dense)               (None, 8, 8, 42)          43050     \n",
      "=================================================================\n",
      "Total params: 12,400,466\n",
      "Trainable params: 1,616,938\n",
      "Non-trainable params: 10,783,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PL8kH57yv1uX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.RMSprop(learning_rate=1e-3)\n",
    "\n",
    "model.compile(optimizer = opt ,loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zVtjur35v1uc"
   },
   "outputs": [],
   "source": [
    "# batch_size = int(len(train_df)/256) 1\n",
    "fitbatch_size = 1\n",
    "nb_epoch = 3\n",
    "# STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "EARLY_STOP_PATIENCE = 3\n",
    "\n",
    "cb_early_stopper = EarlyStopping(monitor = 'categorical_accuracy', patience = EARLY_STOP_PATIENCE)\n",
    "cb_checkpointer = ModelCheckpoint(filepath = pro_dir+'model5/model5_best.h5', monitor = 'val_loss', save_best_only = True, mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hCcXBI0Pv1ur",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import save_model\n",
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "# model.save(pro_dir+'model4/model4_batch1882and1.h5')\n",
    "model=load_model(pro_dir+'model5/model5_best.h5')\n",
    "print('Model Loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (7110, 42) was passed for an output of shape (None, 8, 8, 42) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-74a35f1aee9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcb_checkpointer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcb_early_stopper\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#               validation_steps=3128/batch_size,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m               verbose = 1)\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    707\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         shuffle=shuffle)\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2690\u001b[0m           \u001b[1;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2691\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[1;32m-> 2692\u001b[1;33m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[0;32m   2693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m       \u001b[1;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[1;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[0;32m    547\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[0;32m    548\u001b[0m                            \u001b[1;34m' was passed for an output of shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                            \u001b[1;34m' while using as loss `'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m                            \u001b[1;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m                            'as the output.')\n",
      "\u001b[1;31mValueError\u001b[0m: A target array with shape (7110, 42) was passed for an output of shape (None, 8, 8, 42) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4,decay=1e-6)\n",
    "\n",
    "model.compile(optimizer = opt ,loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
    "# Train model\n",
    "history = model.fit(\n",
    "              X_train,y_train,\n",
    "              batch_size = 1,\n",
    "              validation_data=(X_valid,y_valid),\n",
    "              epochs = 10,\n",
    "              callbacks=[cb_checkpointer, cb_early_stopper],\n",
    "#               validation_steps=3128/batch_size,\n",
    "              verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b5gLnZ3tv1uw",
    "outputId": "d01fb60d-4498-4a88-a3f3-38a7f3c17c5a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12186 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "test_df = pd.read_csv(pro_dir+'test.csv')\n",
    "# convert test to array\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "# 1 2 3 6 9 18 677 1354 2031 4062 6093\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = test_df,\n",
    "    directory = test_dir,\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=1,\n",
    "    x_col = 'filename',\n",
    "    y_col = None,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    seed = 666\n",
    ")\n",
    "#generator will return batch_x，batch_y\n",
    "test_img  = test_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.8470589 , 0.86274517, 0.86666673],\n",
       "         [0.8470589 , 0.86274517, 0.86666673],\n",
       "         [0.8470589 , 0.86274517, 0.86666673],\n",
       "         ...,\n",
       "         [0.8000001 , 0.8000001 , 0.8078432 ],\n",
       "         [0.8000001 , 0.8000001 , 0.8078432 ],\n",
       "         [0.7843138 , 0.7843138 , 0.79215693]],\n",
       "\n",
       "        [[0.8431373 , 0.8588236 , 0.86274517],\n",
       "         [0.8470589 , 0.86274517, 0.86666673],\n",
       "         [0.854902  , 0.8705883 , 0.8745099 ],\n",
       "         ...,\n",
       "         [0.7960785 , 0.7960785 , 0.80392164],\n",
       "         [0.79215693, 0.79215693, 0.8000001 ],\n",
       "         [0.7803922 , 0.7803922 , 0.78823537]],\n",
       "\n",
       "        [[0.854902  , 0.8705883 , 0.8745099 ],\n",
       "         [0.854902  , 0.8705883 , 0.8745099 ],\n",
       "         [0.854902  , 0.8705883 , 0.8745099 ],\n",
       "         ...,\n",
       "         [0.79215693, 0.7843138 , 0.7960785 ],\n",
       "         [0.79215693, 0.7843138 , 0.78823537],\n",
       "         [0.7803922 , 0.77647066, 0.7607844 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8235295 , 0.83921576, 0.8431373 ],\n",
       "         [0.8235295 , 0.83921576, 0.8431373 ],\n",
       "         [0.8235295 , 0.83921576, 0.8431373 ],\n",
       "         ...,\n",
       "         [0.8705883 , 0.8705883 , 0.8705883 ],\n",
       "         [0.8588236 , 0.8588236 , 0.8588236 ],\n",
       "         [0.86274517, 0.86274517, 0.86274517]],\n",
       "\n",
       "        [[0.8117648 , 0.82745105, 0.8313726 ],\n",
       "         [0.8235295 , 0.83921576, 0.8431373 ],\n",
       "         [0.8235295 , 0.83921576, 0.8431373 ],\n",
       "         ...,\n",
       "         [0.86666673, 0.86666673, 0.86666673],\n",
       "         [0.8588236 , 0.8588236 , 0.8588236 ],\n",
       "         [0.86274517, 0.86274517, 0.86274517]],\n",
       "\n",
       "        [[0.8196079 , 0.8352942 , 0.83921576],\n",
       "         [0.8235295 , 0.83921576, 0.8431373 ],\n",
       "         [0.8235295 , 0.83921576, 0.8431373 ],\n",
       "         ...,\n",
       "         [0.86666673, 0.86666673, 0.86666673],\n",
       "         [0.8588236 , 0.8588236 , 0.8588236 ],\n",
       "         [0.8588236 , 0.8588236 , 0.8588236 ]]],\n",
       "\n",
       "\n",
       "       [[[0.46274513, 0.5372549 , 0.59607846],\n",
       "         [0.47058827, 0.54509807, 0.6039216 ],\n",
       "         [0.47058827, 0.54509807, 0.6117647 ],\n",
       "         ...,\n",
       "         [0.80392164, 0.8352942 , 0.8431373 ],\n",
       "         [0.8000001 , 0.8313726 , 0.83921576],\n",
       "         [0.7960785 , 0.8352942 , 0.83921576]],\n",
       "\n",
       "        [[0.4666667 , 0.5411765 , 0.6       ],\n",
       "         [0.47058827, 0.54509807, 0.6039216 ],\n",
       "         [0.47058827, 0.54509807, 0.6117647 ],\n",
       "         ...,\n",
       "         [0.8196079 , 0.85098046, 0.8588236 ],\n",
       "         [0.81568635, 0.8470589 , 0.854902  ],\n",
       "         [0.80392164, 0.8431373 , 0.8470589 ]],\n",
       "\n",
       "        [[0.44705886, 0.53333336, 0.58431375],\n",
       "         [0.45098042, 0.5372549 , 0.5921569 ],\n",
       "         [0.4666667 , 0.5411765 , 0.6       ],\n",
       "         ...,\n",
       "         [0.8117648 , 0.8431373 , 0.85098046],\n",
       "         [0.8078432 , 0.83921576, 0.8470589 ],\n",
       "         [0.80392164, 0.8431373 , 0.8470589 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.7372549 , 0.73333335, 0.7137255 ],\n",
       "         [0.5254902 , 0.52156866, 0.5019608 ],\n",
       "         [0.627451  , 0.62352943, 0.6039216 ],\n",
       "         ...,\n",
       "         [0.70980394, 0.70980394, 0.70980394],\n",
       "         [0.81568635, 0.81568635, 0.81568635],\n",
       "         [0.6784314 , 0.6784314 , 0.6784314 ]],\n",
       "\n",
       "        [[0.6509804 , 0.64705884, 0.627451  ],\n",
       "         [0.427451  , 0.42352945, 0.4039216 ],\n",
       "         [0.74509805, 0.7411765 , 0.72156864],\n",
       "         ...,\n",
       "         [0.7137255 , 0.7137255 , 0.7137255 ],\n",
       "         [0.654902  , 0.654902  , 0.654902  ],\n",
       "         [0.86274517, 0.8588236 , 0.87843144]],\n",
       "\n",
       "        [[0.48627454, 0.48235297, 0.47450984],\n",
       "         [0.6627451 , 0.65882355, 0.6392157 ],\n",
       "         [0.40000004, 0.39607847, 0.37647063],\n",
       "         ...,\n",
       "         [0.87843144, 0.87843144, 0.87843144],\n",
       "         [0.9058824 , 0.9058824 , 0.9058824 ],\n",
       "         [0.8941177 , 0.8941177 , 0.8941177 ]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X[100:103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ESCqu0Dbv1uz",
    "outputId": "141276bb-20b4-46b4-ea9e-05e940b7c4d4"
   },
   "outputs": [],
   "source": [
    "test_name = \"test_img(%s x %s)\" % (IMG_SIZE,IMG_SIZE)\n",
    "\n",
    "with h5py.File( pro_dir +test_name + '.h5', 'w') as hf:\n",
    "    hf.create_dataset(test_name,  data = test_img)\n",
    "\n",
    "# could not broadcast input array from shape (3293,80,80,3) into shape (3293)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGzGJo0nv1u-",
    "outputId": "cd8457f1-27fe-4233-a6c6-74ede3806cc3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/12186 [..............................] - ETA: 0sWARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 12186 batches). You may need to use the repeat() function when building your dataset.\n",
      "    1/12186 [..............................] - 0s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "\n",
    "Y_pred = model.predict (test_img,\n",
    "                        steps=12186,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 8, 0], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_indices=np.argmax(Y_pred,axis=1)\n",
    "predicted_class_indices[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "# for i in range(0, len(predictions)): \n",
    "#     predictions[i] = int(predictions[i]) \n",
    "prediction = np.array(predictions,dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zV1yFfDGv1vC"
   },
   "outputs": [],
   "source": [
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"filename\":filenames,\n",
    "                      \"category\":predictions})\n",
    "results['category'] = results['category'].astype(np.int64)\n",
    "results.to_csv(pro_dir+\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21229,
     "status": "ok",
     "timestamp": 1593556225723,
     "user": {
      "displayName": "Erica Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gipd7DL-9yWsf8_WjRf273iXBUybNkHksq5tuZj=s64",
      "userId": "12108208774374877865"
     },
     "user_tz": -480
    },
    "id": "cmZpZxMSv1vF",
    "outputId": "70ca98ed-608c-40a6-b4b3-b052f52c4da3"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int64' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-37a94410a65d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#     if len(train_df)%int(i)==0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#         print(i,end=' ')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'category'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "\n",
    "results['category'][1].type\n",
    "#記得把0換成00 以此類推"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 941"
     ]
    }
   ],
   "source": [
    "# for i in range(1,len(train_df)):\n",
    "#     if 941%int(i)==0:\n",
    "#         print(i,end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "product detection1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
